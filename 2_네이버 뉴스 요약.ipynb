{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 뉴스 요약\n",
    "* 입력 : 네이버 뉴스 url, 요약 비율\n",
    "* 출력 : matrix 혹은 그래프 활용 textrank 구현 이용한 문서 요약\n",
    "\n",
    "출력 : 요약문(요약비율 적용), 원문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "from konlpy.tag import Komoran\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=105&oid=277&aid=0004511484'\n",
    "resp = requests.get(url)\n",
    "soup = bs(resp.content)\n",
    "Text = soup.select('div._article_body_contents')[0].text\\\n",
    ".replace('// flash 오류를 우회하기 위한 함수 추가','')\\\n",
    ".replace('function _flash_removeCallback() {}','').strip()\n",
    "body = re.sub(r'\\[\\w{0,10} ?[가-힣]{2,5} ? 기자|\\]|\\n|\\t|\\w{0,5} ?기자 ?[a-zA-Z]*@[a-zA-Z]*.*','', Text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "komoran= Komoran()\n",
    "komoTokens = komoran.pos(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     글꼴\n",
       "1     부리\n",
       "2    화면용\n",
       "3    사용자\n",
       "4     개발\n",
       "5     마루\n",
       "6     한글\n",
       "7    네이버\n",
       "8     새롭\n",
       "9     설계\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i in range(len(komoTokens)):\n",
    "    if komoTokens[i][1]=='NNG' and komoTokens[i+1][1] == 'XSN':\n",
    "        komoTokens[i] = re.sub(\"\\', \\'NNG\\'\\) ?\\(\\'\", \"\", str(komoTokens[i])+str(komoTokens[i+1]))\n",
    "        komoTokens[i] = eval(re.sub(\"XSN\", \"NNG\", komoTokens[i]))\n",
    "stopPos = re.sub(\"\\(.{1,15}\\'(E\\w{1,2}|J\\w{1,2}|XS\\w|SE|SF|SO|SP|SS|SW|VCP)\\'\\),? ?\",\"\",str(komoTokens))\n",
    "stopwords = re.sub(\"\\(\\'(등|들|있)\\', \\'\\w{1,3}\\'\\),? ?\",\"\", stopPos)\n",
    "onlyText = re.sub(\"\\(|,? ?\\'\\w{1,3}\\'\\)\",\"\",stopwords)\n",
    "prodText = eval(onlyText)\n",
    "voca = list(set(prodText))\n",
    "voca_len = len(voca)\n",
    "\n",
    "pd.DataFrame(Counter(prodText).most_common()[:10])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_weight (sentence, keywords):\n",
    "    sen_list = sentence.split(' ')\n",
    "    window_start = 0; window_end = -1;\n",
    "    # 탐색이 아니라 문장 내 중요한 키워드를 계산하기 위한 윈도우\n",
    "    \n",
    "    for i in range(len(sen_list)):\n",
    "        if sen_list[i] in keywords:\n",
    "            window_start = i\n",
    "            break\n",
    "            \n",
    "    for i in range(len(sen_list) -1, 0, -1):\n",
    "        if sen_list[i] in keywords:\n",
    "            window_end = i\n",
    "            break\n",
    "    \n",
    "    if window_start > window_end :\n",
    "        return 0\n",
    "    \n",
    "    window_size = window_end - window_start + 1\n",
    "    \n",
    "    keywords_cnt = 0\n",
    "    for w in sen_list :\n",
    "        if w in keywords:\n",
    "            keywords_cnt +=1\n",
    "    return keywords_cnt*keywords_cnt/window_size\n",
    "\n",
    "def summarize(content, max_no_of_sentences = 10):\n",
    "    \n",
    "    txt = content\n",
    "    word_list = get_words(txt)\n",
    "    keywords = get_keywords(word_list, 0.01, 0.5)\n",
    "    print(keywords)\n",
    "    \n",
    "    sentence_list = get_sentences(txt)\n",
    "    sentence_weight = []\n",
    "    for sen in sentence_list:\n",
    "        sentence_weight.append((get_sentence_weight(sen, keywords), sen))\n",
    "    sentence_weight.sort(reverse=True)\n",
    "    ret_list = []\n",
    "    ret_cnt = min(max_no_of_sentences, len(sentence_list))\n",
    "    \n",
    "    for i in range(ret_cnt):\n",
    "        ret_list.append (str(sentence_weight[i][0])+':'+sentence_weight[i][1]+'.')\n",
    "    return ret_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
