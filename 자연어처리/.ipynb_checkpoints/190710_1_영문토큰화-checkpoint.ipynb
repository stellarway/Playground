{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"And yes, she does mean everybody's job from yours to mine and onward to the role of grain farmers in Egypt, pastry chefs in Paris and dog walkers in Oregon i.e. every job. We will now be able to help direct all workers’ actions and behavior with a new degree of intelligence that comes from predictive analytics, all stemming from the AI engines we will now increasingly depend upon.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.forbes.com/sites/adrianbridgwater/2019/04/15/what-drove-the-ai-renaissance/?ss=ai-big-data#45dd5dd61f25'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text,'html.parser')\n",
    "\n",
    "eng_news = soup.select('p') #[class=\"speakable-paragraph\"]')\n",
    "eng_text = eng_news[3].get_text()\n",
    "\n",
    "eng_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.4)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.12.0)\n",
      "Requirement already satisfied: singledispatch in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (3.4.0.3)\n"
     ]
    }
   ],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barack', 'Obama', 'likes', 'fride', 'chicken', 'very', 'much']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "token1 = word_tokenize('Barack Obama likes fride chicken very much')\n",
    "print(token1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['And', 'yes', ',', 'she', 'does', 'mean', 'everybody', \"'s\", 'job', 'from', 'yours', 'to', 'mine', 'and', 'onward', 'to', 'the', 'role', 'of', 'grain', 'farmers', 'in', 'Egypt', ',', 'pastry', 'chefs', 'in', 'Paris', 'and', 'dog', 'walkers', 'in', 'Oregon', 'i.e', '.', 'every', 'job', '.', 'We', 'will', 'now', 'be', 'able', 'to', 'help', 'direct', 'all', 'workers', '’', 'actions', 'and', 'behavior', 'with', 'a', 'new', 'degree', 'of', 'intelligence', 'that', 'comes', 'from', 'predictive', 'analytics', ',', 'all', 'stemming', 'from', 'the', 'AI', 'engines', 'we', 'will', 'now', 'increasingly', 'depend', 'upon', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "token1 = word_tokenize(eng_text)\n",
    "print(token1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['And', 'yes', ',', 'she', 'does', 'mean', 'everybody', \"'\", 's', 'job', 'from', 'yours', 'to', 'mine', 'and', 'onward', 'to', 'the', 'role', 'of', 'grain', 'farmers', 'in', 'Egypt', ',', 'pastry', 'chefs', 'in', 'Paris', 'and', 'dog', 'walkers', 'in', 'Oregon', 'i', '.', 'e', '.', 'every', 'job', '.', 'We', 'will', 'now', 'be', 'able', 'to', 'help', 'direct', 'all', 'workers', '’', 'actions', 'and', 'behavior', 'with', 'a', 'new', 'degree', 'of', 'intelligence', 'that', 'comes', 'from', 'predictive', 'analytics', ',', 'all', 'stemming', 'from', 'the', 'AI', 'engines', 'we', 'will', 'now', 'increasingly', 'depend', 'upon', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "token2 = WordPunctTokenizer().tokenize(eng_text)\n",
    "print(token2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['And', 'yes', ',', 'she', 'does', 'mean', 'everybody', \"'s\", 'job', 'from', 'yours', 'to', 'mine', 'and', 'onward', 'to', 'the', 'role', 'of', 'grain', 'farmers', 'in', 'Egypt', ',', 'pastry', 'chefs', 'in', 'Paris', 'and', 'dog', 'walkers', 'in', 'Oregon', 'i.e.', 'every', 'job.', 'We', 'will', 'now', 'be', 'able', 'to', 'help', 'direct', 'all', 'workers', '’', 'actions', 'and', 'behavior', 'with', 'a', 'new', 'degree', 'of', 'intelligence', 'that', 'comes', 'from', 'predictive', 'analytics', ',', 'all', 'stemming', 'from', 'the', 'AI', 'engines', 'we', 'will', 'now', 'increasingly', 'depend', 'upon', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer as Tree\n",
    "# 정규표현식에 기반한 처리\n",
    "token = Tree().tokenize(eng_text)\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('And', 'CC'),\n",
      " ('yes', 'UH'),\n",
      " (',', ','),\n",
      " ('she', 'PRP'),\n",
      " ('does', 'VBZ'),\n",
      " ('mean', 'VB'),\n",
      " ('everybody', 'NN'),\n",
      " (\"'s\", 'POS'),\n",
      " ('job', 'NN'),\n",
      " ('from', 'IN'),\n",
      " ('yours', 'NNS'),\n",
      " ('to', 'TO'),\n",
      " ('mine', 'VB'),\n",
      " ('and', 'CC'),\n",
      " ('onward', 'VB'),\n",
      " ('to', 'TO'),\n",
      " ('the', 'DT'),\n",
      " ('role', 'NN'),\n",
      " ('of', 'IN'),\n",
      " ('grain', 'NN'),\n",
      " ('farmers', 'NNS'),\n",
      " ('in', 'IN'),\n",
      " ('Egypt', 'NNP'),\n",
      " (',', ','),\n",
      " ('pastry', 'NN'),\n",
      " ('chefs', 'NNS'),\n",
      " ('in', 'IN'),\n",
      " ('Paris', 'NNP'),\n",
      " ('and', 'CC'),\n",
      " ('dog', 'NN'),\n",
      " ('walkers', 'NNS'),\n",
      " ('in', 'IN'),\n",
      " ('Oregon', 'NNP'),\n",
      " ('i.e', 'NN'),\n",
      " ('.', '.'),\n",
      " ('every', 'DT'),\n",
      " ('job', 'NN'),\n",
      " ('.', '.'),\n",
      " ('We', 'PRP'),\n",
      " ('will', 'MD'),\n",
      " ('now', 'RB'),\n",
      " ('be', 'VB'),\n",
      " ('able', 'JJ'),\n",
      " ('to', 'TO'),\n",
      " ('help', 'VB'),\n",
      " ('direct', 'VB'),\n",
      " ('all', 'DT'),\n",
      " ('workers', 'NNS'),\n",
      " ('’', 'VBP'),\n",
      " ('actions', 'NNS'),\n",
      " ('and', 'CC'),\n",
      " ('behavior', 'NN'),\n",
      " ('with', 'IN'),\n",
      " ('a', 'DT'),\n",
      " ('new', 'JJ'),\n",
      " ('degree', 'NN'),\n",
      " ('of', 'IN'),\n",
      " ('intelligence', 'NN'),\n",
      " ('that', 'WDT'),\n",
      " ('comes', 'VBZ'),\n",
      " ('from', 'IN'),\n",
      " ('predictive', 'JJ'),\n",
      " ('analytics', 'NNS'),\n",
      " (',', ','),\n",
      " ('all', 'DT'),\n",
      " ('stemming', 'VBG'),\n",
      " ('from', 'IN'),\n",
      " ('the', 'DT'),\n",
      " ('AI', 'NNP'),\n",
      " ('engines', 'VBZ'),\n",
      " ('we', 'PRP'),\n",
      " ('will', 'MD'),\n",
      " ('now', 'RB'),\n",
      " ('increasingly', 'RB'),\n",
      " ('depend', 'VBP'),\n",
      " ('upon', 'NN'),\n",
      " ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "taggedToken = pos_tag(token1)\n",
    "from pprint import pprint\n",
    "pprint(taggedToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Barack/NNP)\n",
      "  (ORGANIZATION Obama/NNP)\n",
      "  likes/VBZ\n",
      "  fride/RB\n",
      "  chicken/VBN\n",
      "  very/RB\n",
      "  much/JJ)\n"
     ]
    }
   ],
   "source": [
    "neToken=ne_chunk(taggedToken)\n",
    "print(neToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running->run\n",
      "studying->studi\n",
      "running->run\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps=PorterStemmer()\n",
    "print('running->'+ps.stem('running'))\n",
    "print('studying->'+ps.stem('studying'))\n",
    "print('running->'+ps.stem('running'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "studies->study\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wl=WordNetLemmatizer()\n",
    "print(\"studies->\"+wl.lemmatize(\"studies\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopPos=['IN','CC', 'UH', 'TO', 'MD','DT','VBZ','VBP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((',', ','), 3),\n",
       " (('from', 'IN'), 3),\n",
       " (('to', 'TO'), 3),\n",
       " (('and', 'CC'), 3),\n",
       " (('in', 'IN'), 3),\n",
       " (('.', '.'), 3),\n",
       " (('job', 'NN'), 2),\n",
       " (('the', 'DT'), 2),\n",
       " (('of', 'IN'), 2),\n",
       " (('will', 'MD'), 2),\n",
       " (('now', 'RB'), 2),\n",
       " (('all', 'DT'), 2),\n",
       " (('And', 'CC'), 1),\n",
       " (('yes', 'UH'), 1),\n",
       " (('she', 'PRP'), 1),\n",
       " (('does', 'VBZ'), 1),\n",
       " (('mean', 'VB'), 1),\n",
       " (('everybody', 'NN'), 1),\n",
       " ((\"'s\", 'POS'), 1),\n",
       " (('yours', 'NNS'), 1),\n",
       " (('mine', 'VB'), 1),\n",
       " (('onward', 'VB'), 1),\n",
       " (('role', 'NN'), 1),\n",
       " (('grain', 'NN'), 1),\n",
       " (('farmers', 'NNS'), 1),\n",
       " (('Egypt', 'NNP'), 1),\n",
       " (('pastry', 'NN'), 1),\n",
       " (('chefs', 'NNS'), 1),\n",
       " (('Paris', 'NNP'), 1),\n",
       " (('dog', 'NN'), 1),\n",
       " (('walkers', 'NNS'), 1),\n",
       " (('Oregon', 'NNP'), 1),\n",
       " (('i.e', 'NN'), 1),\n",
       " (('every', 'DT'), 1),\n",
       " (('We', 'PRP'), 1),\n",
       " (('be', 'VB'), 1),\n",
       " (('able', 'JJ'), 1),\n",
       " (('help', 'VB'), 1),\n",
       " (('direct', 'VB'), 1),\n",
       " (('workers', 'NNS'), 1),\n",
       " (('’', 'VBP'), 1),\n",
       " (('actions', 'NNS'), 1),\n",
       " (('behavior', 'NN'), 1),\n",
       " (('with', 'IN'), 1),\n",
       " (('a', 'DT'), 1),\n",
       " (('new', 'JJ'), 1),\n",
       " (('degree', 'NN'), 1),\n",
       " (('intelligence', 'NN'), 1),\n",
       " (('that', 'WDT'), 1),\n",
       " (('comes', 'VBZ'), 1),\n",
       " (('predictive', 'JJ'), 1),\n",
       " (('analytics', 'NNS'), 1),\n",
       " (('stemming', 'VBG'), 1),\n",
       " (('AI', 'NNP'), 1),\n",
       " (('engines', 'VBZ'), 1),\n",
       " (('we', 'PRP'), 1),\n",
       " (('increasingly', 'RB'), 1),\n",
       " (('depend', 'VBP'), 1),\n",
       " (('upon', 'NN'), 1)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(taggedToken).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['she', 'mean', 'everybody', \"'s\", 'job', 'yours', 'mine', 'onward', 'role', 'grain', 'farmers', 'Egypt', 'pastry', 'chefs', 'Paris', 'dog', 'walkers', 'Oregon', 'i.e', '.', 'job', '.', 'We', 'now', 'help', 'direct', 'workers', 'actions', 'behavior', 'new', 'degree', 'intelligence', 'that', 'predictive', 'analytics', 'stemming', 'AI', 'we', 'now', 'increasingly', 'upon', '.']\n"
     ]
    }
   ],
   "source": [
    "stopWord=[',','be','able']\n",
    "\n",
    "word = []\n",
    "for tag in taggedToken:\n",
    "    if tag[1] not in stopPos:\n",
    "        if tag[0] not in stopWord:\n",
    "            word.append(tag[0])\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
