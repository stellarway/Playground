{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = ['ants', 'bees']\n",
    "\n",
    "data = []\n",
    "label = []\n",
    "for i, d in enumerate(dirs):\n",
    "    files = os.listdir('./data/hymenoptera_data/'+d)\n",
    "for f in files:\n",
    "    img=Image.open('./data/hymenoptera_data/'+d+'/'+f, 'r')\n",
    "    resize_img = img.resize((128,128))\n",
    "    \n",
    "    r,g,b = resize_img.split()\n",
    "    r_resize_img = np.asarray(np.float32(r)/255.0)\n",
    "    g_resize_img = np.asarray(np.float32(g)/255.0)\n",
    "    b_resize_img = np.asarray(np.float32(b)/255.0)\n",
    "    rgb_resize_img = np.asarray([r_resize_img, g_resize_img, b_resize_img])\n",
    "    data.append(rgb_resize_img)\n",
    "    \n",
    "    label.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype='float32')\n",
    "label = np.array(label, dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = model_selection.train_test_split(data, label, test_size=.1)\n",
    "\n",
    "print(len(train_X))\n",
    "print(len(test_X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X=torch.from_numpy(train_X).float()\n",
    "train_y=torch.from_numpy(train_y).long()\n",
    "\n",
    "# print(train_X.shape)\n",
    "# print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.7961, 0.9490, 0.9529,  ..., 0.1137, 0.2392, 0.1294],\n",
      "         [0.8431, 0.9412, 0.9216,  ..., 0.0902, 0.0510, 0.0706],\n",
      "         [0.8353, 0.9373, 0.9216,  ..., 0.0784, 0.1059, 0.1294],\n",
      "         ...,\n",
      "         [0.2471, 0.2588, 0.0549,  ..., 0.0627, 0.0314, 0.0471],\n",
      "         [0.3647, 0.3412, 0.1255,  ..., 0.2784, 0.0275, 0.0353],\n",
      "         [0.3490, 0.3843, 0.1216,  ..., 0.1843, 0.0471, 0.0549]],\n",
      "\n",
      "        [[0.7059, 0.8745, 0.8588,  ..., 0.0902, 0.2314, 0.0941],\n",
      "         [0.7529, 0.8667, 0.8824,  ..., 0.0784, 0.0471, 0.0745],\n",
      "         [0.7451, 0.8667, 0.8824,  ..., 0.0745, 0.1020, 0.1451],\n",
      "         ...,\n",
      "         [0.1961, 0.2431, 0.0863,  ..., 0.0627, 0.0314, 0.0510],\n",
      "         [0.2745, 0.3255, 0.1412,  ..., 0.2431, 0.0078, 0.0392],\n",
      "         [0.2549, 0.3647, 0.1412,  ..., 0.1333, 0.0275, 0.0588]],\n",
      "\n",
      "        [[0.5412, 0.7176, 0.7490,  ..., 0.0039, 0.1725, 0.0353],\n",
      "         [0.5804, 0.7098, 0.7451,  ..., 0.0039, 0.0000, 0.0039],\n",
      "         [0.5725, 0.7098, 0.7412,  ..., 0.0039, 0.0314, 0.0471],\n",
      "         ...,\n",
      "         [0.0706, 0.1373, 0.0039,  ..., 0.0235, 0.0000, 0.0196],\n",
      "         [0.1490, 0.1412, 0.0353,  ..., 0.1765, 0.0000, 0.0078],\n",
      "         [0.1529, 0.2000, 0.0235,  ..., 0.0667, 0.0039, 0.0275]]]), tensor(1))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = TensorDataset(train_X, train_y)\n",
    "print(train[0])\n",
    "train_loader = DataLoader(train, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(20*29*29, 50)\n",
    "        self.fc2 = nn.Linear(50,2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, 20*29*29)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-c7c421cc2555>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=.001)\n",
    "\n",
    "for epoch in range(300):\n",
    "    total_loss=0\n",
    "    for train_x, train_y in train_loader:\n",
    "#         train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item[0] \n",
    "    if (epoch+1)%50 == 0:\n",
    "        print(epoch+1, total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
